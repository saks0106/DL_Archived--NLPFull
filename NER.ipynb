{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFTVqdA5/tmaAV1MClbvre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saks0106/DL_Frequent_Lookout/blob/main/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LSwkIJYi9CP",
        "outputId": "d66428e8-9463-40d6-afa7-ff94ba3605f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-11 16:22:30--  https://lazyprogrammer.me/course_files/nlp/ner_train.pkl\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3031::6815:17d2, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4757208 (4.5M) [application/octet-stream]\n",
            "Saving to: ‘ner_train.pkl’\n",
            "\n",
            "ner_train.pkl       100%[===================>]   4.54M  14.4MB/s    in 0.3s    \n",
            "\n",
            "2023-10-11 16:22:31 (14.4 MB/s) - ‘ner_train.pkl’ saved [4757208/4757208]\n",
            "\n",
            "--2023-10-11 16:22:31--  https://lazyprogrammer.me/course_files/nlp/ner_test.pkl\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3031::6815:17d2, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1201978 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘ner_test.pkl’\n",
            "\n",
            "ner_test.pkl        100%[===================>]   1.15M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-11 16:22:31 (8.68 MB/s) - ‘ner_test.pkl’ saved [1201978/1201978]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "# conll 2003\n",
        "!wget -nc https://lazyprogrammer.me/course_files/nlp/ner_train.pkl\n",
        "!wget -nc https://lazyprogrammer.me/course_files/nlp/ner_test.pkl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ner_train.pkl', 'rb') as f:\n",
        "  corpus_train = pickle.load(f)\n",
        "\n",
        "with open('ner_test.pkl', 'rb') as f:\n",
        "  corpus_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "nbRUR-RSi9uC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = []\n",
        "train_targets = []\n",
        "\n",
        "for sentence_tag_pairs in corpus_train:\n",
        "  tokens = []\n",
        "  target = []\n",
        "  for token, tag in sentence_tag_pairs:\n",
        "    tokens.append(token)\n",
        "    target.append(tag)\n",
        "  train_inputs.append(tokens)\n",
        "  train_targets.append(target)\n",
        "test_inputs = []\n",
        "test_targets = []\n",
        "\n",
        "for sentence_tag_pairs in corpus_test:\n",
        "  tokens = []\n",
        "  target = []\n",
        "  for token, tag in sentence_tag_pairs:\n",
        "    tokens.append(token)\n",
        "    target.append(tag)\n",
        "  test_inputs.append(tokens)\n",
        "  test_targets.append(target)"
      ],
      "metadata": {
        "id": "pLkA74cli_16"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, Bidirectional\n",
        "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "oI0mgW4NjB6Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentences to sequences\n",
        "\n",
        "MAX_VOCAB_SIZE = None\n",
        "\n",
        "# capitalization might be useful - test it\n",
        "should_lowercase = False\n",
        "word_tokenizer = Tokenizer(\n",
        "    num_words=MAX_VOCAB_SIZE,\n",
        "    lower=should_lowercase,\n",
        "    oov_token='UNK',\n",
        ")\n",
        "# otherwise unknown tokens will be removed and len(input) != len(target)\n",
        "# input words and target words will not be aligned!\n",
        "\n",
        "# it's ok to \"fit\" on the whole corpus - it just means some embeddings\n",
        "# won't be trained\n",
        "# this is because for the test set, any unknown tokens will be removed\n",
        "# which will change the length of the input (***CHECK)\n",
        "\n",
        "word_tokenizer.fit_on_texts(train_inputs)\n",
        "train_inputs_int = word_tokenizer.texts_to_sequences(train_inputs)\n",
        "test_inputs_int = word_tokenizer.texts_to_sequences(test_inputs)"
      ],
      "metadata": {
        "id": "zz2zJZpOjD8r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get word -> integer mapping\n",
        "word2idx = word_tokenizer.word_index\n",
        "V = len(word2idx)\n",
        "print('Found %s unique tokens.' % V)\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/questions/11264684/flatten-list-of-lists\n",
        "def flatten(list_of_lists):\n",
        "  flattened = [val for sublist in list_of_lists for val in sublist]\n",
        "  return flattened\n",
        "\n",
        "all_train_targets = set(flatten(train_targets))\n",
        "all_train_targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaOoUDtGjFep",
        "outputId": "3ef44c8d-e5df-4343-a8e6-8cae19c68088"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 23299 unique tokens.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_targets = set(flatten(test_targets))\n",
        "all_test_targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8XwjamVjJ3P",
        "outputId": "85159e6c-c395-4781-c04a-55ffac00008e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_targets == all_test_targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya0bgo_ujL50",
        "outputId": "906fd632-d0b6-43a5-d9d5-8bb94e173e26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert targets to sequences\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(train_targets)\n",
        "train_targets_int = tag_tokenizer.texts_to_sequences(train_targets)\n",
        "test_targets_int = tag_tokenizer.texts_to_sequences(test_targets)\n",
        "\n",
        "# save for later\n",
        "train_targets_int_unpadded = train_targets_int\n",
        "test_targets_int_unpadded = test_targets_int"
      ],
      "metadata": {
        "id": "_wTY7qSPjOAM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before padding, find max document length\n",
        "# because we don't want to truncate any inputs\n",
        "# which would also truncate targets\n",
        "maxlen_train = max(len(sent) for sent in train_inputs)\n",
        "maxlen_test = max(len(sent) for sent in test_inputs)\n",
        "T = max((maxlen_train, maxlen_test))\n"
      ],
      "metadata": {
        "id": "cFhucSc9jPmu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pad sequences so that we get a N x T matrix\n",
        "train_inputs_int = pad_sequences(train_inputs_int, maxlen=T)\n",
        "print('Shape of data train tensor:', train_inputs_int.shape)\n",
        "\n",
        "test_inputs_int = pad_sequences(test_inputs_int, maxlen=T)\n",
        "print('Shape of data test tensor:', test_inputs_int.shape)\n",
        "\n",
        "train_targets_int = pad_sequences(train_targets_int, maxlen=T)\n",
        "print('Shape of train targets tensor:', train_targets_int.shape)\n",
        "\n",
        "test_targets_int = pad_sequences(test_targets_int, maxlen=T)\n",
        "print('Shape of test targets tensor:', test_targets_int.shape)\n",
        "\n",
        "# number of classes\n",
        "K = len(tag_tokenizer.word_index) + 1\n",
        "K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaBQqWCejRyN",
        "outputId": "0f0ee773-2e3a-4a85-a9ae-7aa328ea9c3f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data train tensor: (12733, 113)\n",
            "Shape of data test tensor: (2970, 113)\n",
            "Shape of train targets tensor: (12733, 113)\n",
            "Shape of test targets tensor: (2970, 113)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "\n",
        "# We get to choose embedding dimensionality\n",
        "D = 32\n",
        "\n",
        "# Note: we actually want to the size of the embedding to (V + 1) x D,\n",
        "# because the first index starts from 1 and not 0.\n",
        "# Thus, if the final index of the embedding matrix is V,\n",
        "# then it actually must have size V + 1.\n",
        "\n",
        "i = Input(shape=(T,))\n",
        "# mask_zero=True way slower on GPU than CPU!\n",
        "x = Embedding(V + 1, D, mask_zero=True)(i)\n",
        "x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
        "# x = SimpleRNN(32, return_sequences=True)(x)\n",
        "x = Dense(K)(x)\n",
        "\n",
        "model = Model(i, x)\n"
      ],
      "metadata": {
        "id": "VfsGdtuZjYk1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and fit\n",
        "model.compile(\n",
        "  loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 60s per epoch on CPU\n",
        "\n",
        "print('Training model...')\n",
        "r = model.fit(\n",
        "  train_inputs_int,\n",
        "  train_targets_int,\n",
        "  epochs=5,\n",
        "  validation_data=(test_inputs_int, test_targets_int)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ihGRfbjbkV",
        "outputId": "c5465c49-077d-4fcb-fd85-07c019116cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/5\n",
            "398/398 [==============================] - 101s 211ms/step - loss: 0.7304 - accuracy: 0.8376 - val_loss: 0.4844 - val_accuracy: 0.8632\n",
            "Epoch 2/5\n",
            " 23/398 [>.............................] - ETA: 47s - loss: 0.3545 - accuracy: 0.8764"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss per iteration\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "LQWJa2gpjdEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "V5DgWmEXjepS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True model accuracy - above includes padding\n",
        "\n",
        "# first get length of each sequence\n",
        "train_lengths = []\n",
        "for sentence in train_inputs:\n",
        "  train_lengths.append(len(sentence))\n",
        "\n",
        "test_lengths = []\n",
        "for sentence in test_inputs:\n",
        "  test_lengths.append(len(sentence))"
      ],
      "metadata": {
        "id": "56oQuWdJjf6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_probs = model.predict(train_inputs_int) # N x T x K\n",
        "train_predictions = []\n",
        "for probs, length in zip(train_probs, train_lengths):\n",
        "  # probs is T x K\n",
        "  probs_ = probs[-length:]\n",
        "  preds = np.argmax(probs_, axis=1)\n",
        "  train_predictions.append(preds)\n",
        "\n",
        "# flatten\n",
        "flat_train_predictions = flatten(train_predictions)\n",
        "flat_train_targets = flatten(train_targets_int_unpadded)"
      ],
      "metadata": {
        "id": "8Qmngt4TjhUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = model.predict(test_inputs_int) # N x T x K\n",
        "test_predictions = []\n",
        "for probs, length in zip(test_probs, test_lengths):\n",
        "  # probs is T x K\n",
        "  probs_ = probs[-length:]\n",
        "  preds = np.argmax(probs_, axis=1)\n",
        "  test_predictions.append(preds)\n",
        "\n",
        "# flatten\n",
        "flat_test_predictions = flatten(test_predictions)\n",
        "flat_test_targets = flatten(test_targets_int_unpadded)"
      ],
      "metadata": {
        "id": "_3p7qlAzjlJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "print(\"Train acc:\", accuracy_score(flat_train_targets, flat_train_predictions))\n",
        "print(\"Test acc:\", accuracy_score(flat_test_targets, flat_test_predictions))\n",
        "\n",
        "print(\"Train f1:\", f1_score(flat_train_targets, flat_train_predictions, average='macro'))\n",
        "print(\"Test f1:\", f1_score(flat_test_targets, flat_test_predictions, average='macro'))"
      ],
      "metadata": {
        "id": "u5NibT2bjmlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Baseline model: map word to tag\n",
        "from collections import Counter\n",
        "\n",
        "# https://stackoverflow.com/questions/1518522/find-the-most-common-element-in-a-list\n",
        "def most_common(lst):\n",
        "    data = Counter(lst)\n",
        "    return data.most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "y5chQYDwjn4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2tags = {k: [] for k, v in word2idx.items()}\n",
        "\n",
        "# remove UNK token\n",
        "del token2tags['UNK']\n",
        "\n",
        "for tokens, tags in zip(train_inputs, train_targets):\n",
        "  for token, tag in zip(tokens, tags):\n",
        "    if should_lowercase:\n",
        "      token = token.lower()\n",
        "    if token in token2tags:\n",
        "      token2tags[token].append(tag)\n",
        "\n",
        "for k, v in token2tags.items():\n",
        "  if len(v) == 0:\n",
        "    print(k)\n",
        "\n",
        "token2tag = {k: most_common(v) for k, v in token2tags.items()}"
      ],
      "metadata": {
        "id": "tuSgAEmsjpay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute accuracy\n",
        "\n",
        "train_predictions = []\n",
        "for sentence in train_inputs:\n",
        "  predictions = []\n",
        "  for token in sentence:\n",
        "    if should_lowercase:\n",
        "      token = token.lower()\n",
        "    predicted_tag = token2tag[token]\n",
        "    predictions.append(predicted_tag)\n",
        "  train_predictions.append(predictions)\n",
        "flat_train_predictions = flatten(train_predictions)\n",
        "flat_train_targets = flatten(train_targets)\n",
        "\n",
        "\n",
        "\n",
        "test_predictions = []\n",
        "for sentence in test_inputs:\n",
        "  predictions = []\n",
        "  for token in sentence:\n",
        "    predicted_tag = token2tag.get(token, 'INCORRECT')\n",
        "    predictions.append(predicted_tag)\n",
        "  test_predictions.append(predictions)\n",
        "flat_test_predictions = flatten(test_predictions)\n",
        "flat_test_targets = flatten(test_targets)"
      ],
      "metadata": {
        "id": "HuLigsygjrK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train acc:\", accuracy_score(flat_train_targets, flat_train_predictions))\n",
        "print(\"Test acc:\", accuracy_score(flat_test_targets, flat_test_predictions))\n",
        "\n",
        "print(\"Train f1:\", f1_score(flat_train_targets, flat_train_predictions, average='macro'))\n",
        "print(\"Test f1:\", f1_score(flat_test_targets, flat_test_predictions, average='macro'))"
      ],
      "metadata": {
        "id": "vQuzJyRFjuik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQoBMNqajwdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}